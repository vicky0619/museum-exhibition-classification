

### English Version

# Museum Exhibition Classification Project

## ğŸ“– Project Overview
This project is a **Museum Object Classification** solution that uses **YOLO (You Only Look Once) object detection model** and an **anti-reflection model** to identify artifacts and artworks in museums and exhibition halls. It aims to enhance the accuracy of object recognition by removing reflections from images and then performing classification on the cleaned images.

Competition Website: https://aigo.org.tw/zh-tw/competitions/details/507

## âœ¨ Key Features
- **YOLO Object Detection**: Identifies and classifies museum objects from captured images, supporting multiple categories.
- **Anti-Reflection Model**: Improves image quality by reducing reflections, enhancing object recognition accuracy.
- **Dual Detection Result Comparison**: Compares results from the original image and the reflection-removed image, selecting the best classification.

## âš™ï¸ System Requirements
- iOS 14 or later
- Xcode 12.0 or later
- TensorFlow Lite

## ğŸ›  Installation Steps
1. **Clone the Repository**
   ```bash
   git clone https://github.com/yourusername/museum-exhibition-classification.git
   cd museum-exhibition-classification
   ```
2. **Open Project**
   - Open Xcode and select `museum_classification.xcodeproj`.

3. **Install Dependencies**
   - Ensure TensorFlow Lite is installed. You can use CocoaPods or manually import it into your project.

4. **Add Model Files**
   - Place the `epoch300_float32.tflite` and `aigo_model_v1.tflite` model files in the `Resources` directory of the project.

## ğŸš€ Usage
1. **Open Camera**: Click on the "Open Camera" button to capture an image.
2. **Process Photo**: Click on the "Process Photo" button to execute both YOLO detection and anti-reflection processes. The app will display the best classification result once completed.
3. **Save Image**: The reflection-removed image will automatically be saved to your photo library.

## ğŸ“‚ Project Structure
```bash
museum_classification/
â”œâ”€â”€ CameraViewModel.swift       # Core logic for camera functionality and model inference
â”œâ”€â”€ ContentView.swift           # SwiftUI design for the user interface
â”œâ”€â”€ ImagePicker.swift           # Image capture logic
â”œâ”€â”€ Resources/                  # TensorFlow Lite model files
â””â”€â”€ README.md                   # Project documentation
```

## ğŸ’¡ Future Improvements
- **Performance Optimization**: Improve the accuracy and speed of both the anti-reflection and object classification models.
- **Multi-Language Support**: Provide localized versions for users from different regions.
- **Expanded Applications**: Adapt the model for other object recognition scenarios such as libraries, art exhibitions, etc.

## ğŸ¤ Contribution
We welcome **Issues** and **Pull Requests**! Here's how you can contribute:
1. Fork this repository.
2. Create a feature branch (`git checkout -b feature/YourFeature`).
3. Commit your changes (`git commit -m 'Add YourFeature'`).
4. Push to the branch (`git push origin feature/YourFeature`).
5. Open a Pull Request.

## ğŸ“§ Contact
If you have any questions or suggestions about this project, feel free to reach out at: [vicky46586038@gmail.com](mailto:vicky46586038@gmail.com).

---

---

### ä¸­æ–‡ç‰ˆæœ¬

# åšç‰©é¤¨å±•è¦½ç‰©ä»¶åˆ†é¡é …ç›®

## ğŸ“– é …ç›®æ¦‚è¿°
æœ¬é …ç›®æ˜¯ä¸€å€‹**åšç‰©é¤¨ç‰©ä»¶åˆ†é¡**è§£æ±ºæ–¹æ¡ˆï¼Œä½¿ç”¨ **YOLO ç‰©ä»¶æª¢æ¸¬æ¨¡å‹** å’Œ **æ¶ˆåå…‰æ¨¡å‹** ä¾†è­˜åˆ¥åšç‰©é¤¨å’Œå±•è¦½é¤¨ä¸­çš„æ–‡ç‰©å’Œè—è¡“å“ã€‚è©²é …ç›®æ—¨åœ¨é€šéæ¶ˆé™¤åœ–åƒä¸­çš„åå…‰ä¾†æé«˜ç‰©ä»¶è­˜åˆ¥çš„æº–ç¢ºæ€§ï¼Œä¸¦å°è™•ç†å¾Œçš„åœ–åƒé€²è¡Œåˆ†é¡ã€‚

ç«¶è³½ç¶²ç«™: https://aigo.org.tw/zh-tw/competitions/details/507

## âœ¨ ä¸»è¦ç‰¹é»
- **YOLO ç‰©ä»¶æª¢æ¸¬**ï¼šå¾æ‹æ”çš„åœ–åƒä¸­è­˜åˆ¥ä¸¦åˆ†é¡åšç‰©é¤¨ç‰©ä»¶ï¼Œæ”¯æŒå¤šç¨®é¡åˆ¥ã€‚
- **æ¶ˆåå…‰æ¨¡å‹**ï¼šé€šéé™ä½åå…‰ä¾†æ”¹å–„åœ–åƒè³ªé‡ï¼Œæé«˜ç‰©ä»¶è­˜åˆ¥çš„æº–ç¢ºæ€§ã€‚
- **é›™é‡æª¢æ¸¬çµæœæ¯”è¼ƒ**ï¼šæ¯”è¼ƒåŸå§‹åœ–åƒå’Œæ¶ˆé™¤åå…‰å¾Œçš„åœ–åƒçµæœï¼Œé¸æ“‡æœ€ä½³åˆ†é¡ã€‚

## âš™ï¸ ç³»çµ±éœ€æ±‚
- iOS 14 æˆ–æ›´é«˜ç‰ˆæœ¬
- Xcode 12.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- TensorFlow Lite

## ğŸ›  å®‰è£æ­¥é©Ÿ
1. **å…‹éš†å„²å­˜åº«**
   ```bash
   git clone https://github.com/yourusername/museum-exhibition-classification.git
   cd museum-exhibition-classification
   ```
2. **æ‰“é–‹å°ˆæ¡ˆ**
   - æ‰“é–‹ Xcode ä¸¦é¸æ“‡ `museum_classification.xcodeproj`ã€‚

3. **å®‰è£ä¾è³´é …**
   - ç¢ºä¿å·²å®‰è£ TensorFlow Liteã€‚æ‚¨å¯ä»¥ä½¿ç”¨ CocoaPods æˆ–æ‰‹å‹•å°å…¥åˆ°æ‚¨çš„å°ˆæ¡ˆä¸­ã€‚

4. **æ·»åŠ æ¨¡å‹æ–‡ä»¶**
   - å°‡ `epoch300_float32.tflite` å’Œ `aigo_model_v1.tflite` æ¨¡å‹æ–‡ä»¶æ”¾å…¥å°ˆæ¡ˆçš„ `Resources` ç›®éŒ„ä¸­ã€‚

## ğŸš€ ä½¿ç”¨æ–¹å¼
1. **é–‹å•Ÿç›¸æ©Ÿ**ï¼šæŒ‰ä¸‹ "Open Camera" æŒ‰éˆ•ä¾†æ•æ‰åœ–åƒã€‚
2. **è™•ç†ç›¸ç‰‡**ï¼šæŒ‰ä¸‹ "Process Photo" æŒ‰éˆ•ä¾†åŸ·è¡Œ YOLO æª¢æ¸¬å’Œæ¶ˆåå…‰è™•ç†ã€‚è™•ç†å®Œæˆå¾Œï¼Œæ‡‰ç”¨ç¨‹å¼æœƒé¡¯ç¤ºæœ€ä½³åˆ†é¡çµæœã€‚
3. **ä¿å­˜åœ–åƒ**ï¼šæ¶ˆé™¤åå…‰å¾Œçš„åœ–åƒå°‡è‡ªå‹•ä¿å­˜åˆ°æ‚¨çš„ç›¸å†Šã€‚

## ğŸ“‚ å°ˆæ¡ˆçµæ§‹
```bash
museum_classification/
â”œâ”€â”€ CameraViewModel.swift       # ç›¸æ©ŸåŠŸèƒ½å’Œæ¨¡å‹æ¨ç†çš„æ ¸å¿ƒé‚è¼¯
â”œâ”€â”€ ContentView.swift           # ç”¨æ–¼ç”¨æˆ¶ç•Œé¢çš„ SwiftUI è¨­è¨ˆ
â”œâ”€â”€ ImagePicker.swift           # åœ–åƒæ•æ‰é‚è¼¯
â”œâ”€â”€ Resources/                  # TensorFlow Lite æ¨¡å‹æ–‡ä»¶
â””â”€â”€ README.md                   # å°ˆæ¡ˆæ–‡ä»¶
```

## ğŸ’¡ æœªä¾†æ”¹é€²
- **æ€§èƒ½å„ªåŒ–**ï¼šæ”¹é€²æ¶ˆåå…‰å’Œç‰©ä»¶åˆ†é¡æ¨¡å‹çš„æº–ç¢ºæ€§å’Œé€Ÿåº¦ã€‚
- **å¤šèªè¨€æ”¯æŒ**ï¼šæä¾›ä¸åŒåœ°å€ç”¨æˆ¶çš„æœ¬åœ°åŒ–ç‰ˆæœ¬ã€‚
- **æ“´å±•æ‡‰ç”¨**ï¼šå°‡æ¨¡å‹æ‡‰ç”¨æ–¼å…¶ä»–ç‰©ä»¶è­˜åˆ¥å ´æ™¯ï¼Œä¾‹å¦‚åœ–æ›¸é¤¨ã€è—è¡“å±•è¦½ç­‰ã€‚

## ğŸ¤ è²¢ç»
æˆ‘å€‘æ­¡è¿ **å•é¡Œå›å ±** å’Œ **Pull Requests**ï¼ä»¥ä¸‹æ˜¯è²¢ç»çš„æ–¹æ³•ï¼š

1. **Fork æœ¬å„²å­˜åº«**ã€‚
2. **å»ºç«‹ä¸€å€‹åŠŸèƒ½åˆ†æ”¯** (`git checkout -b feature/YourFeature`)ã€‚
3. **æäº¤æ‚¨çš„æ›´æ”¹** (`git commit -m 'Add YourFeature'`)ã€‚
4. **æ¨é€åˆ°åˆ†æ”¯** (`git push origin feature/YourFeature`)ã€‚
5. **é–‹å•Ÿ Pull Request**ã€‚

## ğŸ“§ è¯çµ¡æ–¹å¼
å¦‚æœæ‚¨å°æœ¬é …ç›®æœ‰ä»»ä½•ç–‘å•æˆ–å»ºè­°ï¼Œè«‹éš¨æ™‚è¯ç¹«æˆ‘å€‘ï¼š[vicky46586038@gmail.com](mailto:vicky46586038@gmail.com)ã€‚

